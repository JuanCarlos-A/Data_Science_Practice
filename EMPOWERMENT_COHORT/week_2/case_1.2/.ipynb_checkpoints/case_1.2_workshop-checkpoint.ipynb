{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are trading volume and volatility related for energy stocks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "1_min"
    ]
   },
   "source": [
    "## Goals\n",
    "\n",
    "In this lab, we will be replicating some of the analyses we conducted in the main lecture. You will gain more familiarity with the `pandas` library, which was introduced in the pre-foundational Python program, and will learn how to do basic feature engineering, how to plot distributions and how to calculate summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Importing the required libraries\n",
    "\n",
    "Let's start by importing `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas package\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import a second package, `matplotlib`, which is the basic Python library for plotting. We are interested only in the `pyplot` module, so we run this (here we use `plt` as the alias for the `pyplot` module that comes with the `matplotlib` package - `plt` as an alias is customary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matplotlib package (for plotting)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "## Basic feature engineering\n",
    "\n",
    "As you know, we can create new columns (also known as features) in our dataset using data from other columns. This is often useful when the existing features aren't in the right format or unit, or don't provide a lot of information by themselves.\n",
    "\n",
    "Let's load in the CSV file for the stock symbol `D`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a file as a DataFrame and assign to the variable name D\n",
    "D = pd.read_csv(\"data/D.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, our DataFrame has 6 columns (`Date`, `Open`, `High`, `Low`, `Close`, and `Volume`) and one default index (the vertical sequence of integers in bold to the left of the table).\n",
    "\n",
    "It is usually a good idea to set one of the columns as the index, instead of using the default. We can do that with the **`.set_index()`** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = D.set_index('Date') # In this context, Date is the best candidate to be the index\n",
    "D.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Load the other four datasets, namely `DUK.csv`, `EXC.csv`, `NEE.csv`, and `SO.csv`, and assign their contents to variables whose name is the symbol (that is, `DUK.csv` should be assigned to the variable `DUK`, and so on). Don't forget to set `Date` as the index for each one of the DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** Shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "outputs": [],
   "source": [
    "DUK = pd.read_csv(\"data/DUK.csv\")\n",
    "DUK = DUK.set_index('Date')\n",
    "\n",
    "EXC = pd.read_csv(\"data/EXC.csv\")\n",
    "EXC = EXC.set_index('Date')\n",
    "\n",
    "NEE = pd.read_csv(\"data/NEE.csv\")\n",
    "NEE = NEE.set_index('Date')\n",
    "\n",
    "SO = pd.read_csv(\"data/SO.csv\")\n",
    "SO = SO.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### The `symbol`  column\n",
    "\n",
    "To create a new column in `pandas`, you use this syntax:\n",
    "\n",
    "~~~python\n",
    "my_dataframe[\"name_of_new_column\"] = the_definition_of_the_new_column\n",
    "~~~\n",
    "\n",
    "So, to create a new column with the name of the symbol, you use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[\"Symbol\"] = \"D\"\n",
    "D.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we defined a new column called `Symbol` and asked `pandas` to assign the string value `D` to *all* of its rows. Let's create the corresponding `Symbol` column in `DUK`, `EXC`, `NEE` and `SO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUK[\"Symbol\"] = \"DUK\"\n",
    "EXC[\"Symbol\"] = \"EXC\"\n",
    "NEE[\"Symbol\"] = \"NEE\"\n",
    "SO[\"Symbol\"] = \"SO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "1_min"
    ]
   },
   "source": [
    "#### Concatenating our DataFrame\n",
    "\n",
    "Below we stitch all the dataframes together with the `pd.concat()` function (we will need this concatenated DataFrame in a moment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.concat([D, DUK, EXC, NEE, SO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7_min"
    ]
   },
   "source": [
    "### The `Return` column\n",
    "\n",
    "This is the daily return formula:\n",
    "\n",
    "$$\n",
    "Return = \\frac{Close_t}{Close_{t-1}} - 1\n",
    "$$\n",
    "\n",
    "Let's look at our DataFrame `D` (we only show  the first three rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute $Return$ for July 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_2_july = 61.730\n",
    "close_3_july = 60.863\n",
    "return_3_july = (close_3_july / close_2_july) - 1\n",
    "print(return_3_july)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could write a `for` loop to do this operation on each of the rows one by one, but thankfully `pandas` offers us an easier way - the **`.shift()`** method. The `.shift()` method takes a Series and shifts it up or down (depending on your input) in relation to the index of the Series. This is better understood with an example - here's the head of the `High` Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[\"High\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the `High` price for July 3 was 61.394.\n",
    "\n",
    "You can shift the Series so that the value that is associated with July 3 is no longer its own, but rather the one corresponding to July 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[\"High\"].head(5).shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can, of course, reverse the direction of the shift and move the whole Series \"downwards\" instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[\"High\"].head(5).shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can shift it as many rows as you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[\"High\"].head(5).shift(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "\n",
    "This is the formula we want to code:\n",
    "\n",
    "$$\n",
    "Return = \\frac{Close_t}{Close_{t-1}} - 1\n",
    "$$\n",
    "\n",
    "Getting $Close_t$ is easy:\n",
    "\n",
    "~~~python\n",
    "D[\"Close\"]\n",
    "~~~\n",
    "\n",
    "But how would you get its shifted version, $Close_{t-1}$?\n",
    "\n",
    "**Hint:** Let's say $t=30$. You would then want to get $Close_{29}$. So, in your table, the row for $t=30$ should have a column that contains $Close_{30}$ (this one already exists, it's in `Close`) and another one (call it `Close_Previous`) that contains $Close_{29}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** Shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "outputs": [],
   "source": [
    "D[\"Close_Previous\"] = D[\"Close\"].shift(1)\n",
    "D.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "How would you code the definition of `Return`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "outputs": [],
   "source": [
    "D[\"Return\"] = (D[\"Close\"] / D[\"Close_Previous\"]) - 1.0\n",
    "D.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### Trading volume in millions\n",
    "\n",
    "Recall the formula:\n",
    "\n",
    "$$\n",
    "Volume\\_Millions = \\frac{Volume}{1,000,000}\n",
    "$$\n",
    "\n",
    "You probably remember that you can divide in Python using the `/` symbol. Since `pandas` Series support Python arithmetic, you can simply do this in order to create the new column (notice that we now use the concatenated DataFrame `stocks` instead of the `D` DataFrame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks[\"Volume_Millions\"] = stocks[\"Volume\"] / 1000000\n",
    "stocks.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "### A measure of volatility\n",
    "\n",
    "This is another formula that we need to replicate in our concatenated DataFrame:\n",
    "\n",
    "$$\n",
    "VolStat = \\frac{High_t - Low_t}{Open_t}\n",
    "$$\n",
    "\n",
    "Let's add it to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks[\"VolStat\"] = (stocks[\"High\"] - stocks[\"Low\"]) / stocks[\"Open\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "## Creating histograms\n",
    "\n",
    "This is a histogram of the `Volume_Millions` column in `stocks` (therefore it includes the data for all five symbols). Here we use the `.plot.hist()` method and accept the default bins that Pandas calculates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvm = stocks['Volume_Millions'].plot.hist()\n",
    "\n",
    "hvm.set_title(\"Histogram of Volume_Millions\")\n",
    "hvm.set_xlabel(\"Millions of shares\")\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "Plot the histogram of the `Open` column in `stocks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** This is the histogram of the `Open` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ho = stocks['Open'].plot.hist()\n",
    "\n",
    "ho.set_title(\"Histogram of Open\")\n",
    "ho.set_xlabel(\"USD\")\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Summary statistics\n",
    "\n",
    "### Minimum, maximum, mean and median\n",
    "\n",
    "To find the minimum, maximum, mean, median, and mode of a distribution, we can use these functions:\n",
    "\n",
    "~~~python\n",
    ".min()\n",
    ".max()\n",
    ".mean()\n",
    ".median()\n",
    ".mode()\n",
    "~~~\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks[\"Close\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### Percentiles\n",
    "\n",
    "To compute the $p$-th percentile, you use\n",
    "\n",
    "~~~python\n",
    "my_series.quantile(per/100)\n",
    "~~~\n",
    "\n",
    "The resulting number will be such that $p$% of your data points are smaller than that value. So, for instance, if you want to find the $p=30$ percentile (a value such that 30% of your data points are smaller than that value), you need to pass 0.3 to the function, like this:\n",
    "\n",
    "~~~python\n",
    "my_series.quantile(0.3)\n",
    "~~~\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per0 = stocks[\"Close\"].quantile(0)\n",
    "per25 = stocks[\"Close\"].quantile(0.25)\n",
    "per50 = stocks[\"Close\"].quantile(0.50)\n",
    "per75 = stocks[\"Close\"].quantile(0.75)\n",
    "per100 = stocks[\"Close\"].quantile(1)\n",
    "\n",
    "print(per0)\n",
    "print(per25)\n",
    "print(per50)\n",
    "print(per75)\n",
    "print(per100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "## Using `.groupby()`\n",
    "\n",
    "We can easily calculate the summary statistics for any given column with the **`.describe()`** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks[\"Volume_Millions\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it would be more useful if we computed the summary statistics *for each symbol individually.* Let's group our `stocks` DataFrame by `Symbol`. The resulting `DataFrameGroupBy` object should have five elements, because there are five symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = stocks.groupby(['Symbol'])\n",
    "len(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is basically the `VolStat` column split up into five chunks, one for each stock symbol.\n",
    "\n",
    "The real power of `.groupby()` is evident when you pair it with **aggregation functions** like `sum()`, `mean()` and others. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.groupby(['Symbol'])[\"VolStat\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "4_min"
    ]
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Copy the preceding code and modify it to run the `.describe()` function on the grouped `VolStat` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "outputs": [],
   "source": [
    "stocks.groupby(['Symbol'])[\"VolStat\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the output we wanted. We have the summary statistics of the `VolStat` column *for each symbol*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "8_min"
    ]
   },
   "source": [
    "## Plotting the time series\n",
    "\n",
    "Let's now plot the `VolStat` time series. Since we have several stocks, we can use one series for each stock.\n",
    "\n",
    "This bit that follows is important because you'll see it a lot in professional practice. Let's first find out what data type our index is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can see that this index is of `dtype='object'`, which means that for `pandas` its elements are not dates, but rather simple strings. If we were to plot our variables using this index as the time axis, we could get a lot of unexpected and weird behaviors. That's why it is always advised to cast our columns into the appropriate data types before plotting or doing analyses with them.\n",
    "\n",
    "Let's convert this index to the `datetime` data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.index = pd.to_datetime(stocks.index)\n",
    "stocks.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you see that our new data type is `datetime64[ns]`, which is what we wanted. For more details about the `datetime` data type, check the [docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html).\n",
    "\n",
    "The actual plot is very easy to make. You just take the `SeriesGroupBy` object that corresponds to `VolStat` and call the `.plot()` method on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.groupby(\"Symbol\")[\"VolStat\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plots one series for each symbol. The output is accurate, but the plot looks somewhat raw at the moment. Let's add the all-important legend and a title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.groupby(\"Symbol\")[\"VolStat\"].plot(legend=True, title=\"Energy Sector Trends - VolStat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's make it a bit bigger with the `figsize` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.groupby(\"Symbol\")[\"VolStat\"].plot(legend=True,\n",
    "                                         title=\"Energy Sector Trends - VolStat\",\n",
    "                                         figsize=(15,6)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution\n",
    "\n",
    "\"Reshaping and pivot\" (modified from the original), Pandas Developers, [BSD-3 license](https://github.com/pandas-dev/pandas/blob/master/LICENSE), https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html.\n",
    "\n",
    "\n",
    "\"Huge Stock Market Dataset\", No. 10, 2017, Boris Marjanovic, Public Domain. https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs"
   ]
  }
 ],
 "metadata": {
  "c1_recart": "6.0.0-57c20131aabc1dc2a8c675852d80a7da"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
