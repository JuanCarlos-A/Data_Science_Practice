{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic DataFrame manipulation in `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Today we will learn how to manipulate tables in Python using the **`pandas`** library.\n",
    "\n",
    "`pandas` stands for \"Python Data Analysis\". It is a Python library that facilitates a wide range of data analysis and manipulation. Before, you saw basic data structures in Python such as lists and dictionaries. While you can build a basic data table using nested lists in Python (similar to an Excel spreadsheet), they get quite difficult to work with. By contrast, in `pandas` the table data structure, known as a **`DataFrame`**, is a first-class citizen and you can easily manipulate your data thinking of it in rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames and Series\n",
    "\n",
    "If you've ever used or heard of R or SQL before, `pandas` brings some functionality from each of these to Python, allowing you to structure and filter data more efficiently than when using pure Python. This efficiency is seen in two distinct ways:\n",
    "\n",
    "* Code written using `pandas` will often run faster than scripts written in pure Python\n",
    "* Code written using `pandas` will often contain far fewer lines of code than the equivalent code written in pure Python\n",
    "\n",
    "At the core of the ```pandas``` library are two fundamental data structures/objects:\n",
    "1. [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)\n",
    "2. [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
    "\n",
    "A **```Series```** object stores single-column data along with an **index**. An index is just a way of \"numbering\" the ```Series``` object.\n",
    "\n",
    "A **```DataFrame```** object is a two-dimensional tabular data structure with labeled axes. It is conceptually helpful to think of a DataFrame object as a collection of Series objects. Namely, think of each column in a DataFrame as a single Series object, where each of these Series objects shares a common index -  the index of the DataFrame object.\n",
    "\n",
    "The following diagrams show the differences between a Series and a DataFrame. This is a DataFrame - notice that it has an index for its columns and an index for its rows:\n",
    "\n",
    "<img src=\"data/images/dataframe.jpg\" alt=\"A Dataframe\" style=\"width: 500px;\"/>\n",
    "\n",
    "If you *slice* a DataFrame to extract just **one** column, you'll get a Series. Series can also be created from scratch, independent of any DataFrame. This is a Series:\n",
    "\n",
    "<img src=\"data/images/series.jpg\" alt=\"A Series\" style=\"width: 600px;\"/>\n",
    "\n",
    "Series don't have column indexes, because they don't have columns. You can, however, give your Series a name.\n",
    "\n",
    "Note that DataFrame objects can also have a single-column â€“ think of this as a DataFrame consisting of a single Series object (they might contain the same information, but are still distinct objects and are treated as such by `pandas`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into `pandas`\n",
    "\n",
    "A popular way of working with data is storing it in **Comma-Separated Values (CSV) files** and then reading those files into Python using Pandas. CSVs are plain-text files that store tables using one CSV row per table row and separate the columns using commas (although other characters are possible, like semicolons):\n",
    "\n",
    "<img src=\"data/images/csv.jpg\" alt=\"A CSV file\" style=\"width: 500px;\"/>\n",
    "\n",
    "To load a CSV file into `pandas`, you first import the library (the `pd` alias is customary) and then call the **`.read_csv()`** function like this:\n",
    "\n",
    "~~~python\n",
    "import pandas as pd\n",
    "pd.read_csv(\"path/to/file.csv\")\n",
    "~~~\n",
    "\n",
    "Let's read our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/watches.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the first 5 rows using **`.head()`** (to see the last 5 we would use `.tail()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset of 75 watches that are sold online (some of them are new, but most are secondhand). There is data for three stores (\"Watches unlimited\", \"National traders\" and \"Super deals\"). The `engagement` column contains a metric of user engagement in the store website, and the `price` column is the price tag.\n",
    "\n",
    "You can access a column using square brackets and quotes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `pandas` assigns a serial number as the index (that's the unnamed column of integers in bold face in the `df.head()` output above), so setting a custom row index that makes sense for your DataFrame is often a good idea. You can set the index of a DataFrame with the **`.set_index()`** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\"model\", \"store\", \"condition\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the columns used as the indexes are emphasized in bold instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping your data\n",
    "\n",
    "Grouping your data by a subset of the variables in the DataFrame is a common task in which `pandas` excels. We use the **`.groupby()`** method to do this. You can think of `groupby()` as a `for` loop that goes through the values of some user-specified column(s) and, in each iteration, extracts only those DataFrame rows that match that value in the specified column. The below diagram visualizes a `groupby()` operation over the column `foo`. Since there are only two values in `foo` (`one` and `two`), there are only two resulting groups:\n",
    "\n",
    "<img src=\"data/images/groupby.jpg\" alt=\"Groupby\" style=\"width: 500px;\"/>\n",
    "\n",
    "Source: Modified from [`pandas` docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html).\n",
    "\n",
    "When you do a group by, you're basically splitting your original DataFrame into smaller chunks, depending on the values of one or more columns.\n",
    "\n",
    "The output of this method is a `DataFrameGroupBy` object. This object can be most readily thought of as containing a smaller DataFrame object for every group. Specifically, each item of the object is a tuple, containing the group identifier (in this case, `one` or `two`) and the rows of the DataFrame that correspond to that identifier.\n",
    "\n",
    "`.groupby()` is most useful when we use it together with **aggregation functions** (functions that summarize our data), like `sum()`, `mean()`, and others. Here we group our dataframe `df` by the `model` and `condition` variables. Inside, the resulting object has all the data from `df`, partitioned into pieces depending on the values of the two variables we grouped by. We then ask `pandas` to compute the mean price for each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby([\"model\", \"condition\"]) # Grouping by\n",
    "groups[\"price\"].mean() # You first slice using [\"price\"] and then call the mean function on the grouped Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to see the contents of the `DataFrameGroupBy` object as such, you can iterate through it using a `for` loop like this:\n",
    "\n",
    "~~~python\n",
    "for group in groups:\n",
    "    print(group)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Repeat the group by + aggregation above, only this time group by `model` alone instead of `model` and `condition`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** Shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "outputs": [],
   "source": [
    "groups2 = df.groupby([\"model\"])\n",
    "groups2[\"price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting\n",
    "\n",
    "**Pivoting** is basically the same as grouping by + aggregating, with the difference that you can have some of the grouping variables as columns instead of as rows. This is sometimes nicer to look at.\n",
    "\n",
    "Let's say you wanted to see the average `price` of each `model` per `condition`. Rather than doing the group by + aggregation we had above, we could use pivoting to get something like this (we made `condition` a set of columns this time):\n",
    "<br><br>\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr>      <th></th>      <th colspan=\"5\" halign=\"left\">price</th>    </tr>    <tr>      <th>condition</th>      <th>Fair</th>      <th>Good</th>      <th>Like new</th>      <th>New</th>      <th>Very Good</th>    </tr>    <tr>      <th>model</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Caracal</th>      <td>2949.5</td>      <td>1744.0</td>      <td>508.0</td>      <td>1818.5</td>      <td>1832.5</td>    </tr>    <tr>      <th>Clepsydra</th>      <td>4151.5</td>      <td>604.0</td>      <td>1934.0</td>      <td>4162.5</td>      <td>1737.0</td>    </tr>    <tr>      <th>Lightning bolt</th>      <td>4235.5</td>      <td>655.0</td>      <td>1739.5</td>      <td>652.5</td>      <td>1783.5</td>    </tr>    <tr>      <th>Sand</th>      <td>4207.5</td>      <td>3006.0</td>      <td>1884.5</td>      <td>543.5</td>      <td>520.0</td>    </tr>    <tr>      <th>Tempo</th>      <td>4189.5</td>      <td>4225.5</td>      <td>3039.5</td>      <td>2965.0</td>      <td>1854.5</td>    </tr>  </tbody></table>\n",
    "\n",
    "This is called a **pivot table**.  You may already familiar with pivot tables if you have previously worked a fair amount in Microsoft Excel.\n",
    "\n",
    "When you pivot, you summarize one of your numeric columns by group, where the groups are determined by some of the other columns. Some of those variables can be shown as rows, and some can be shown as columns. In the table above, we found the mean `price` grouping by `model` (shown as rows) and `condition` (shown as columns).\n",
    "\n",
    "We create pivot tables in `pandas` using the **`.pivot_table()`** method, with this syntax:\n",
    "\n",
    "~~~python\n",
    "pd.pivot_table(my_df, values=[\"numeric_column\"], index=[\"row_variable\"], columns=[\"column_variable\"])\n",
    "~~~\n",
    "\n",
    "`pandas` defaults to summarizing the numeric column using the `.mean()` function (commonly known as average or arithmetic mean). You can use other aggregation functions as well (for more information, check the [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Recreate the pivot table above using the syntax we've just explained and the variables from the `df` DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** Shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values=[\"price\"], index=[\"model\"], columns=[\"condition\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "source": [
    "The resulting data is identical to the data we got using `.groupby()`, but looks a lot nicer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstacking\n",
    "\n",
    "Let's have a look at our original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 75 rows and two columns. If we count the three indexes as columns, that makes 5 columns total.\n",
    "\n",
    "We sometimes want to reduce the number of rows without removing any data points, like when we need to paste our table in a report and want it to fit on a single page. Additionally, having `condition` as a single column makes it difficult to locate the values that correspond to each possible condition (\"New\", \"Like new\", etc.). We can address both these issues using something called **unstacking**.\n",
    "\n",
    "When you unstack a DataFrame, you take its innermost index level (in this case, `condition`) and turn it into a column of its own, and the DataFrame gets rearranged accordingly. This has the consequence of reducing the number of rows in your dataset while increasing the number of columns. In other words, when you unstack, you reshape your DataFrame to change it from a *long form* to a *wide form*.\n",
    "\n",
    "Unstacking in `pandas` is very easy with the **`.unstack()`** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 15 rows and 12 columns (before we had 75 rows and 5 columns). Since we also avoided having to repeat the variable names, this unstacked table takes a lot less space and can be read more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "What is the difference between pivoting and unstacking?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** When you pivot, you do group by + aggregation, and then arrange one or more of the grouping variables as columns. When you unstack, you don't group by and don't aggregate. You simply reshape your DataFrame without changing your data at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "**Stacking** is just the reverse of unstacking. You take a wide DataFrame and make it long. For instance, here we unstack `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_unstacked_df = df.unstack()\n",
    "my_unstacked_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reverse the process using **`.stack()`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Stack `my_unstacked_df` and verify that the result is exactly equal to `df` (the original DataFrame)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ans_cell"
    ]
   },
   "outputs": [],
   "source": [
    "my_unstacked_df.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If you are interested in learning more about DataFrame manipulation in `pandas`, we encourage you to study their very convenient [user guide](https://pandas.pydata.org/docs/user_guide/reshaping.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution\n",
    "\n",
    "\"Reshaping and pivot\" (modified from the original), Pandas Developers, [BSD-3 license](https://github.com/pandas-dev/pandas/blob/master/LICENSE), https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html."
   ]
  }
 ],
 "metadata": {
  "c1_recart": "5.1.0-57c20131aabc1dc2a8c675852d80a7da"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
