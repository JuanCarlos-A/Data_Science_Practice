{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VBLyCk8EJ3t"
   },
   "source": [
    "# Do credit scoring algorithms discriminate against protected groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S63CBEtFHtW",
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Goals\n",
    "\n",
    "By the end of this case study you should be able to:\n",
    "\n",
    "1. Meaningfully interpret summary statistics\n",
    "2. Meaningfully interpret data visualizations\n",
    "3. Think critically about sociological factors at play in the data collected for machine learning applications\n",
    "\n",
    "Most importantly, you will explore how historical & representation bias can creep into training datasets, and bias the final conclusions *in favor* of existing biased practices, thus perpetuating them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6fFriSyFLUT",
    "tags": [
     "8_min"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "**Business Context.** Investigative reports about digital financial services (DFS) have found instances of bias in the mechanisms that determine who a bank should loan money to. In many parts of the world, financial services are typically accessed based on an algorithmic assessment of their credit history. However, these systems have historically excluded consumers who are financially marginalized through intersecting forces of oppression. For example, in the United States, African Americans are disproportionately denied home loans because of a legacy of policies and banking practices implemented decades ago that were designed to exclude Black individuals from home ownership (also known as [Red Lining](https://en.wikipedia.org/wiki/Redlining)). Beyond race or ethnicity, many other factors may contribute to unfair distribution of financial opportunities, such as an applicant's gender, location, or age. \n",
    "\n",
    "In this case, you are a data analyst for a major credit bureau. Your organization is concerned that the data on which they have trained their assessment tools are leading to discriminatory outcomes. The company wants to know if their predictions have been inaccurate for specific subgroups of the population based on how their prediction of credit worthiness was correlated with protected categories (e.g., gender, nationality, age). The company believes that if you can find patterns in the dataset used to build their model that reflect long-standing unfair social determinants of creditworthiness, they can then rectify this to reduce their contribution to unfair outcomes.\n",
    "\n",
    "**Business Problem.** Your employer would like you to answer the following: **\"What are the hidden biases in our datasets used to train our credit risk assessment algorithms?\"**\n",
    "\n",
    "**Analytical Context.** This dataset includes information about individuals and their credit history (whether they had failed to pay their loans before, what other loans they had, etc.) The credit agency will train a model on this data to decide whether to approve individuals for a loan (we typically use something called [*classification models*](https://towardsdatascience.com/supervised-learning-basics-of-classification-and-main-algorithms-c16b06806cd3) for these tasks, which you will learn about in later cases). The model will predict whether the individual will default (stop paying the loan, which is a bad outcome). You can find more information about the dataset [here](http://www1.beuth-hochschule.de/FB_II/reports/Report-2019-004.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "Let's start by importing the necessary libraries and loading in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiCAW75OSU8A"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "b1vSKQjOSxAt",
    "outputId": "883bf826-33c2-4787-c74a-7fedef7ff462"
   },
   "outputs": [],
   "source": [
    "# Load annd examine the dataset\n",
    "df = pd.read_csv('data/german_credit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have provided a description of the most important features and what various values for those features means. Please note that the currency used in this dataset is German Deutsche Mark, which is abbreviated as DM:\n",
    "\n",
    "* **``Id``**: ID of individual entries for evaluation.\n",
    "* **``status``**: Status of the debtor's checking account with the bank.\n",
    "    * `1`: No checking account\n",
    "    * `2`: Negative account balance\n",
    "    * `3`: 0 - 199 DM account balance\n",
    "    * `4`: 200+ DM account balance\n",
    "* **``duration``**: Credit duration, in months.\n",
    "* **``credit_history``**: History of compliance with previous or concurrent credit contracts.\n",
    "    * `0`: Delay in paying off in the past\n",
    "    * `1`: Critical account/other credits elsewhere\n",
    "    * `2`: No credits taken/all credits paid back duly \n",
    "    * `3`: Existing credits paid back duly until now\n",
    "    * `4`: All credits at this bank paid back duly\n",
    "* **``purpose``**: Purpose for which the credit is needed.\n",
    "    * `0`: Others\n",
    "    * `1`: Car (new)\n",
    "    * `2`: Car (used)\n",
    "    * `3`: Furniture/equipment \n",
    "    * `4`: Radio/television\n",
    "    * `5`: Domestic appliances \n",
    "    * `6`: Repairs\n",
    "    * `7`: Education\n",
    "    * `8`: Vacation\n",
    "    * `9`: Retraining\n",
    "    * `10`: Business\n",
    "* **``amount``**: Credit amount in DM.\n",
    "* **``employment_duration``**: Duration of debtor's employment with current employer.\n",
    "    * `1`: Unemployed\n",
    "    * `2`: Less than 1 year\n",
    "    * `3`: 1 - 3 years\n",
    "    * `4`: 4 - 6 years\n",
    "    * `5`: 7+ years\n",
    "* **``installment_rate``**: Credit installments as a percentage of debtor's disposable income.\n",
    "    * `1`: 35%+\n",
    "    * `2`: 25 - 34.99% \n",
    "    * `3`: 20 - 24.99%\n",
    "    * `4`: Less than 20%\n",
    "* **``personal_status_sex``**: Combined information on sex and marital status. (Sex cannot always be recovered from the variable, because male singles and female non-singles are coded with the same code 2. Furthermore, female widows cannot be easily classified, because the code table does not list them in any of the female categories.)\n",
    "    * `1`: Divorced or separated male\n",
    "    * `2`: Single male OR non-single female\n",
    "    * `3`: Married or widowed male\n",
    "    * `4`: Single female\n",
    "* **``other_debtors``**: Whether or not there is another debtor or a guarantor for the credit.\n",
    "    * `1`: None\n",
    "    * `2`: Co-applicant \n",
    "    * `3`: Guarantor\n",
    "* **``present_residence``**: Length of time (in years) the debtor has lived in the present residence.\n",
    "    * `1`: Less than 1 year\n",
    "    * `2`: 1 - 4 years\n",
    "    * `3`: 4 - 7 years \n",
    "    * `4`: 7+ years\n",
    "* **``age``**: Debtor's age, in years.\n",
    "* **``housing``**: Type of housing the debtor lives in.\n",
    "    * `1`: Free\n",
    "    * `2`: Rent\n",
    "    * `3`: Own\n",
    "* **``number_credits``**: Number of credits including the current one the debtor has (or had) at this bank.\n",
    "    * `1`: 1\n",
    "    * `2`: 2 - 3 \n",
    "    * `3`: 4 - 5 \n",
    "    * `4`: 6+\n",
    "* **``job``**: The quality of the debtor's job.\n",
    "    * `1`: Unemployed/unskilled non-resident\n",
    "    * `2`: Unskilled resident\n",
    "    * `3`: Skilled employee/official\n",
    "    * `4`: Manager/self-employed/highly-qualified employee\n",
    "* **``people_liable``**: Number of persons who financially depend on the debtor (i.e. are entitled to maintenance).\n",
    "    * `1`: 3+ \n",
    "    * `2`: 0 - 2\n",
    "* **``foreign_worker``**: Whether or not the debtor is a foreign worker.\n",
    "    * `1`: Yes \n",
    "    * `2`: No\n",
    "* **``credit_risk``**: Whether the credit contract has been complied with (good) or not (bad).\n",
    "    * `0`: Bad\n",
    "    * `1`: Good\n",
    "\n",
    "A full description of the dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMfGxLswSWl1",
    "tags": [
     "15_min"
    ]
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Examine the dataset's summary statistics and the provided visualizations below to better understand the demographic distribution of the data. Briefly summarize your main findings.\n",
    "\n",
    "<img src=\"./data/images/stats_cont_vars.png\" width=\"400\">\n",
    "\n",
    "<img src=\"./data/images/age_hist.png\" width=\"600\">\n",
    "<img src=\"./data/images/age_cred_hist.png\" width=\"600\">\n",
    "\n",
    "<img src=\"./data/images/pers_status_cred.png\" width=\"600\">\n",
    "<img src=\"./data/images/risk_by_gender.png\" width=\"600\">\n",
    "\n",
    "<img src=\"./data/images/job_cred.png\" width=\"600\">\n",
    "<img src=\"./data/images/risk_by_job.png\" width=\"400\">\n",
    "\n",
    "<img src=\"./data/images/foreign_cred.png\" width=\"600\">\n",
    "<img src=\"./data/images/risk_by_foreign.png\" width=\"400\">\n",
    "\n",
    "<img src=\"./data/images/deps_cred.png\" width=\"600\">\n",
    "<img src=\"./data/images/risk_by_deps.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVsQtMT574F9",
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** We want to use the above summary statistics and plots to answer the question: *Who is this dataset representing?*\n",
    "\n",
    "* When examining the age distribution through histograms, we see that it is right-skewed, and that the dataset mainly represents adults in their 20s - 40s, with a mean age of 35 and a median age of 33. We see in the overlapping histogram split on creditworthiness that lower ages (below 25) and higher ages (above 50) seem to have higher percentages of being considered not credit-worthy.\n",
    "* The dataset does not represent the population as a whole. Specifically, only 5% of the data are female entries! The dataset is skewed towards married men who are skilled workers.\n",
    "* Only 3.7% of the dataset were foreign workers; however, this is an interesting point of contention that will be discussed in more detail below, as this is a corrected summary statistic after a mistranslation of the dataset.\n",
    "* Only 16% of the dataset includes individuals with three or more dependents, meaning that individuals with few or no children are overrepresented in the data and parents of large families may be insufficiently represented.\n",
    "* Overall, this dataset is not representative of the South German population, but rather is representative of German working men in their 30s in the 1970s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dks9736DsoPa",
    "tags": [
     "30_min"
    ]
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Learn about the social context of the problem by reading and summarizing research on financial discrimination in the population. For more information on the dataset sampling techniques, visit the [dataset's accompanying report](http://www1.beuth-hochschule.de/FB_II/reports/Report-2019-004.pdf).\n",
    "\n",
    "From there, find one or two other reputable sources (e.g. research papers that have used the dataset, critiques of the dataset, German population reports, German financial industry statistics, German discrimination laws and financial product regulations) to form an opinion about the relevant social context. Summarize your findings and cite your references."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6dgCxcz7Swy",
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** This dataset was collected using a stratified sample of 1,000 credit applicants (300 bad - credit_risk = 0, 700 good - credit_risk = 1) during 1973 - 1975 from a large regional bank in southern Germany [1]. In November of 2019, Ulrike Gromping recognized the code table had been mistranslated and corrected the widely-used dataset, specifically affecting the `foreign_worker`, `people_liable`, and `personal_status_sex` features, meaning that previous inferences based on the uncorrected dataset should be reconsidered under this new context and showing the fragility of the machine learning dataset pipeline [1]. Beyond the issue of the reliability of the data, the non-representativeness of the dataset must be addressed - Fahrmeir and Hamerle (1984) [4] specify that customers with \"good\" credits perfectly complied with the conditions of the contract while customers with \"bad\" credits did not comply with the contract as required, indicating that all members of the dataset were granted credit and thus must have already passed some checks in order to be originally granted credit approval. We know that financial discrimination of the basis of age and gender exist [2] and are based on concerns of how older adults nearing retirement age will be able to repay credit or due to taste-based gender discrimination [3].\n",
    "\n",
    "Women faced a variety structural and social barriers to mortgage financing around this time. For example, 2/3 of loan associations surveyed by the Bank Board identified marital status as a deciding factor in loan decisions. At that time the population of divorced, widowed, or separated women was three times that for men, and those unmarried women were more likely to seek loans because they were more likely to be supporting children. What's more, upon marriage women essentially forfeited their economic identity and thus their ability to build a strong credit history. Never-married women, who could build such a history, were still often denied credit for major purchases like cars and houses. Socially, women were often \"assumed to have less regard for her obligations than, say, a married man\". It was also assumed that women were more likely to leave the labor force and thus be unable to pay back their loans. In Germany specifically, women were not allowed to work without permission from their husband until the year 1977, placing them in a deeply financially-dependent position that could impact their access to financial services.\n",
    "\n",
    "**References**\n",
    "\n",
    "1. Grömping, U. (2019). *South German Credit Data: Correcting a Widely Used Data Set*. Reports in Mathematics, Physics and Chemistry. [Url](http://www1.beuth-hochschule.de/FB_II/reports/Report-2019-004.pdf).\n",
    "2. US. Department of Housing and Urban Development (1999). *What we know about mortgage lending discrimination in America*. HUD-8765-3. [Url](https://www.huduser.gov/publications/pdf/hud-8765-3.pdf) (you can find a copy in the `data` folder as `reference_1.pdf`).\n",
    "3. Montoya, A. *et al.* (2020). *Bad Taste: Gender Discrimination in the Consumer Credit Market*. Inter-American Development Bank Working Paper Series No. IDB-WP-1053. [Url](https://publications.iadb.org/en/bad-taste-gender-discrimination-in-the-consumer-credit-market) (you can find a copy in the `data` folder as `reference_2.pdf`).\n",
    "4. Tritschler, J. (1984). *Fahrmeir, L. and Hamerle, A. (Eds.) (1984). Multivariate statistiche verfahren (in German). Verlag W. de Gruyter, 1984*. Mathematical Social Sciences, vol. 7, issue 3, 311-312. [Url](https://econpapers.repec.org/article/eeematsoc/v_3a7_3ay_3a1984_3ai_3a3_3ap_3a311-312.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xrSL2HLs1z8",
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Look at your answer to Exercise 1 and see if it reflects your findings in Exercise 2. Summarize your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klQ69ig064RC",
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** We find that our summary statistics and plots do indeed appear to reflect the social analysis from Exercise 2. From a gender perspective, the extreme underrepresentation of women in the dataset reinforces the fact that women during 1970s Germany lacked financial autonomy and may not have been able to apply for or obtain credit. The greater rate of guarantors for women further suggest that they may have been financially dependent or entwined with their husbands, and that single or unmarried women may not be represented. Further, we find that \"good\" creditworthiness ratings are less common for individuals under 25, posing a risk for a discriminatory attribute. Moreover, both gender and age may be correlated with attributes used to determine loan eligibility (e.g. occupation and credit history), suggesting that these attributes could be associated with financial discrimination within the dataset and in any models produced using this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIFzeNMtIyl",
    "tags": [
     "15_min"
    ]
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "Focus on two demographic variables - gender and age. Compare the outcomes in each gender group and in each age group using the provided visualizations below. What groups are privileged for age and gender? What do you think are the sources of these disparities?\n",
    "\n",
    "<img src='data/images/gender_cred.png' width=500>\n",
    "<img src='data/images/under_25_cred.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J8NuQmN54Qa",
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** For gender, we believe that men are privileged (and women are underprivileged). As can be seen in the plots generated above, women overall actually have a slightly greater rate of \"good\" creditworthiness than men (77% vs. 75%), though slightly less than \"married\" men (the male average is likely driven down by divorced and single men). However, we believe men to be privileged because of how much more prevalent they are in the dataset than women (comprising about 90% of the dataset), indicating that there could be some societal or legal factors discouraging women from seeking credit, despite the limited sample's comparable rate of \"good\" credit outcome. Further, the fact that gender is segmented further by marital status for men but not for women suggests that there may be additional limitations for women based on their marital status (for example, perhaps unmarried women are ineligible for credit).\n",
    "\n",
    "For age, we believe individuals over age 25 are privileged (and individuals under age 25 are underprivileged). As can be seen in the plots above, young people are materially less likely to have a \"good\" creditworthiness rating than those older than 25 (65% vs. 77%), indicating that being young could place one at a disadvantage for obtaining credit.\n",
    "\n",
    "These disparities for age could arise from young people's relative lack of a financial track record and economic security, which could make them less appealing in the eyes of a lender. As shown above, applicants under age 25 are less likely to have a repayment history with the bank and are less likely to have an executive level job, factors that may be correlated with credit approval. Furthermore, credit lenders might have implicit biases against young people and their ability to repay the loan, perhaps believing them to be less financially stable or responsible. We see this happen even today: young people such as college students often find it hard to obtain their first credit card without a credit history, and often have to resort to being added as an authorized user on a parent's card or applying to \"starter\" cards with low credit limits and fewer benefits than those with more established credit histories.\n",
    "\n",
    "These disparities for gender likely arise from cultural context and women's role within society, expounded by the fact that the data is from 1973 - 1975. Until 1977, women in Germany could not legally work without their husband's permission, as noted above. This would encompass the time period of the dataset, and has a few implications on women's level of privilege. Foremost, lenders would be very unlikely to grant a loan to someone without a source of income to repay it, making women without jobs ineligible. Further, this precludes unmarried women from working, suggesting that unmarried women may also be ineligible for a loan. Further, the fact that married men are so much more represented than women indicates that men are more likely to play a financial role within a family unit. Overall, a lack of rights and financial autonomy render women deeply underprivileged in the context of obtaining credit.\n",
    "\n",
    "Algorithmic discrimination or predictive models can become unethical when they give certain privileged groups advantages while disadvantaging other underprivileged groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heMbip79u1E3",
    "tags": [
     "10_min"
    ]
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "In their [article](https://arxiv.org/pdf/1901.10002.pdf) *A Framework for Understanding Unintended Consequences of Machine Learning*, authors Harini Suresh and John Guttag provide a brief description of various kinds of dataset bias. Specifically, they concretely define the concepts of **historical bias** and **representation bias**. Is our case an example of historical bias, representation bias, or both? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLGIrh275jbn",
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.** Suresh and Gutag define historical bias as bias that arises when there is a misalignment between the world as it is and the values or objectives to be encoded and propagated in a model. They note that it is a normative concern with the state of the world, regardless of if our sampling and analysis methods are perfect.\n",
    "\n",
    "They define representation bias as arising while defining and sampling from a population, occurring when some parts of the population are underrepresented in the sample and thus the conclusions based on the entire sample fail to generalize well to the underrepresented segments.\n",
    "\n",
    "According to the data source, the data was collected via a stratified sample from actual credits, with bad credits heavily oversampled. With the above definitions in mind, the lack of privilege for women is an example of historical bias. As noted above, there were existing biases and restrictions against women in Germany during the period of data collection that inevitably resulted in fewer females being able to apply for credit, which would cause the credit dataset to be biased toward men. With respect to age, it is reasonable to believe that there may have been similar cultural hurdles or biases toward young people obtaining credit, as evidenced by the social context research cited above. For example, Germany did not enact an anti-discrimination law regarding age until 2006, and young people have historically faced challenges obtaining credit due to a lack of credit history (Market Watch, [*More than half of this group of Americans say low credit scores are holding them back*](https://www.marketwatch.com/story/almost-half-of-millennials-say-that-their-credit-scores-are-holding-them-back-2018-07-16)).\n",
    "\n",
    "However, a case can also be made for representation bias in this scenario. As Suresh and Gutag note: \"If some group is a minority that only makes up 5% of the true distribution, then even sampling from the true data distribution will lead to a less robust model for this group.\" In this dataset, women presumably make up a minority of the true distribution, in part because of the historical bias noted above, so would be underrepresented in the ultimate dataset. Further, individuals under age 25 also make up only about 19% of observations. If a model is built on the entire dataset, it will underweight the relevant factors in the underrepresented groups as they will be \"outvoted\" by the data points from the overrepresented groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYl5PWfCvXPK",
    "tags": [
     "10_min"
    ]
   },
   "source": [
    "## Reflection\n",
    "\n",
    "### Discussion 1\n",
    "\n",
    "Reflect on what it means for a dataset to be biased in the context of this case. Then reflect on how this may generalize to other example domains where we may want to examine bias.\n",
    "\n",
    "In this broader context, does a difference in the data across groups constitute a bias in itself? Are there other elements that are necessary to say that there is bias? What are some of those elements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qxzR8yhvb8y",
    "tags": [
     "10_min"
    ]
   },
   "source": [
    "### Discussion 2\n",
    "\n",
    "Reflect on your own biases (e.g. cognitive, social, ideological) you brought to this case study. What messages have you received from media, your education, family, or your peers that may bias your approach to this problem? Did any of the results you saw in the dataset surprise you? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "La2rRnnXvhce",
    "tags": [
     "10_min"
    ]
   },
   "source": [
    "### Discussion 3\n",
    "\n",
    "With a partner, brainstorm ways to assess and address those cognitive biases when working on future data analysis projects. Describe one way you could implement a personal bias check into your own workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYq0FJ7R1NSN",
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "The South German Credit dataset, widely used to build financial services prediction models, is indeed biased. Importantly, we concluded that in this dataset:\n",
    "\n",
    "1. Women are underrepresented compared to men\n",
    "2. People under 25 are underrepresented compared to people over 25\n",
    "3. Foreign workers are overrepresented compared to domestic workers\n",
    "4. Caretakers with many dependents are underrepresented in comparison to those with fewer than 3 dependents\n",
    "\n",
    "We saw that the dataset contained biases that were both historical and representational in nature, and that those two types of biases are intertwined. Historical (societal) biases, for example, may be the reason why underprivileged groups then become underrepresented in datasets. Thus, an investigation into whether or not the credit scoring algorithm your company uses contains biases is warranted. In fact, it is almost certain that the model will perform in ways that reinforce existing barriers for women and young people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mxsZfLm1RM8",
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "## Takeaways\n",
    "\n",
    "In this case study, we learned about two common forms of dataset bias. When datasets are biased, models can become biased, especially if the dataset biases go undetected. We used data exploration techniques to understand the nature of the dataset and reason about how it might reinforce existing social biases. We learned how to perform background and domain research on our datasets to understand where the data is coming from, how it was generated, and what the social context of the data sample was at the time of collection.\n",
    "\n",
    "Most importantly, we practiced critical thinking and self-reflection as we completed this case. It is important that we as data professionals remember that we are social beings bringing our biases, preconceptions, and blind spots to our projects. We should incorporate ways to recognize and account for these biases in our project workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLPKkQ4B1UNO"
   },
   "source": [
    "## Attribution\n",
    "\n",
    "Grömping, U. (2019). South German Credit Data: Correcting a Widely Used Data Set. Report 4/2019, Reports in Mathematics, Physics and Chemistry, Department II, Beuth University of Applied Sciences Berlin."
   ]
  }
 ],
 "metadata": {
  "c1_recart": "6.4.0-57c20131aabc1dc2a8c675852d80a7da"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
